{"cells":[{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/book_recommendation')\n","os.listdir('./data')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_6k_wYziyfX","executionInfo":{"status":"ok","timestamp":1746579135053,"user_tz":420,"elapsed":21107,"user":{"displayName":"Thomas Sarda","userId":"00374335539538120771"}},"outputId":"56ca7e1d-147c-448d-d5ad-dc7da945d59f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["['2000users_120interactions_100000booksample_bert_embeddings_fantasy.json.gz',\n"," 'goodreads_interactions_2k_users_fantasy_paranormal.json.gz',\n"," 'goodreads_interactions_20k_users_book_ids.csv',\n"," 'goodreads_books_fantasy_paranormal.json.gz',\n"," 'smaller_books_100000.json.gz',\n"," 'goodreads_interactions_fantasy_paranormal.json.gz',\n"," 'goodreads_interactions_2k_users_book_ids.csv',\n"," 'goodreads_interactions_2k_users.json.gz']"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["# Verified necessary libraries\n","import numpy as np\n","import pandas as pd\n","import json\n","import gzip"],"metadata":{"id":"40JCZC7hCphM","executionInfo":{"status":"ok","timestamp":1746579135333,"user_tz":420,"elapsed":276,"user":{"displayName":"Thomas Sarda","userId":"00374335539538120771"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"muJKDa_zivVa","executionInfo":{"status":"error","timestamp":1746483940218,"user_tz":420,"elapsed":546,"user":{"displayName":"Thomas Sarda","userId":"00374335539538120771"}},"outputId":"ee34b805-726f-4b38-ba23-de5b9dfeaffe"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'ijson'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-affdf9957c34>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mijson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ijson'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import pandas as pd\n","import ijson\n","import requests\n","import os\n","import gzip\n","import json\n","import re\n","import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","\n","from transformers import BertModel, BertTokenizer\n","import torch\n","\n","from collections import defaultdict, Counter"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HwB6ZmYivVd","executionInfo":{"status":"ok","timestamp":1746579135566,"user_tz":420,"elapsed":230,"user":{"displayName":"Thomas Sarda","userId":"00374335539538120771"}},"outputId":"3e4d6d84-0e2a-4a54-90ca-ca9771475a6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["['2000users_120interactions_100000booksample_bert_embeddings_fantasy.json.gz', 'goodreads_interactions_2k_users_fantasy_paranormal.json.gz', 'goodreads_interactions_20k_users_book_ids.csv', 'goodreads_books_fantasy_paranormal.json.gz', 'smaller_books_100000.json.gz', 'goodreads_interactions_fantasy_paranormal.json.gz', 'goodreads_interactions_2k_users_book_ids.csv', 'goodreads_interactions_2k_users.json.gz']\n"]}],"source":["DIR = './data'\n","print(os.listdir(DIR))\n","USE_SMALLSET = True"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ctYs7y5MivVe","executionInfo":{"status":"ok","timestamp":1746579136080,"user_tz":420,"elapsed":512,"user":{"displayName":"Thomas Sarda","userId":"00374335539538120771"}},"outputId":"85b2fa93-5591-49b0-981d-1af544c772fc"},"outputs":[{"output_type":"stream","name":"stdout","text":[".\n","    book_id\n","0    102969\n","1  25293197\n","2  18080377\n","3  13083783\n","4  25903297\n","book_id    81867\n","dtype: int64\n"]}],"source":["print(os.curdir)\n","df = pd.read_csv(os.path.join(DIR, \"goodreads_interactions_2k_users_book_ids.csv\"))\n","print(df.head())\n","print(df.count())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJuWazBhivVf"},"outputs":[],"source":["def create_smaller_books(file_name, book_id_df, count):\n","    data = []\n","    # convert book ids from dataframe to set\n","    book_ids = book_id_df[\"book_id\"].values.tolist()\n","    book_ids = [str(x) for x in book_ids]\n","    # open gzip and read json lines\n","    outfile_name = os.path.join(DIR,'smaller_books_'+str(count)+'.json.gz')\n","    with gzip.open(file_name, 'rt') as fin, gzip.open(outfile_name, 'wt') as fout:\n","        linecount = 0\n","        for line in fin:\n","            # convert json line to dictionary\n","            book = json.loads(line)\n","            fout.write(line)\n","            linecount += 1\n","            if linecount == count:\n","                break\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgARSFk2ivVf"},"outputs":[],"source":["smaller_book_count = 100000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCsv9qDkivVg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746509794975,"user_tz":420,"elapsed":70790,"user":{"displayName":"Thomas Sarda","userId":"00374335539538120771"}},"outputId":"7836ef03-8da0-45c0-bf92-8028dc4dd310"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":14}],"source":["create_smaller_books(os.path.join(DIR, \"goodreads_books_fantasy_paranormal.json.gz\"), df, smaller_book_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ueYYKnPvivVh"},"outputs":[],"source":["def load_books(file_name, book_id_df, count = -1, max_iter = -1):\n","    data = []\n","    # convert book ids from dataframe to set\n","    book_ids = book_id_df[\"book_id\"].values.tolist()\n","    book_ids = [str(x) for x in book_ids]\n","    # open gzip and read json lines\n","    with gzip.open(file_name, 'rt') as f:\n","        iter = 0\n","        for line in f:\n","            iter += 1\n","            # convert json line to dictionary\n","            book = json.loads(line)\n","            # check if book id is in the set\n","            id = (book['book_id'])\n","            if (book['book_id']) in book_ids:\n","                count -= 1\n","                data.append(book)\n","            if count == 0:\n","                break\n","            if(iter == max_iter):\n","                break\n","        if(iter % 1000 == 0):\n","            print(iter)\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pd8_Fl5sivVh","outputId":"9eaff752-4d11-4161-c41f-450e92c5cc6d","colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"status":"error","timestamp":1746510228089,"user_tz":420,"elapsed":397809,"user":{"displayName":"Thomas Sarda","userId":"00374335539538120771"}}},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-9cfd8a4cb329>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'goodreads_books.json.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_books\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of books: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-0f4a9bcd4858>\u001b[0m in \u001b[0;36mload_books\u001b[0;34m(file_name, book_id_df, count, max_iter)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if(USE_SMALLSET):\n","    infile = 'smaller_books_'+str(smaller_book_count)+'.json.gz'\n","else:\n","    infile = 'goodreads_books.json.gz'\n","\n","books = load_books(os.path.join(DIR, infile), df, -1)\n","print(\"Number of books: \", len(books))\n","print(books[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQbbZa95ivVh"},"outputs":[],"source":["df = pd.DataFrame(books)\n","df.to_json(os.path.join(DIR, \"goodreads_interactions_20k_users_books.json.gz\"), orient=\"records\", compression=\"gzip\")"]},{"cell_type":"markdown","metadata":{"id":"Wb8dNqBAivVi"},"source":["Generate embeddings for obtained books"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXQezSxyivVj","outputId":"764cbe43-0c27-4cde-df30-5130584bd0f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.4474, 0.4698, 0.3909],\n","        [0.5437, 0.8783, 0.3055],\n","        [0.5091, 0.3499, 0.4088],\n","        [0.6373, 0.3073, 0.6229],\n","        [0.6841, 0.4462, 0.5326]])\n"]}],"source":["import torch\n","x = torch.rand(5, 3)\n","print(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["c7b783c9211b42299b5813465e90c87e"]},"id":"mEm1M6G3ivVj","outputId":"aee299f3-0e41-4138-c15a-7fa303d4b6e0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7b783c9211b42299b5813465e90c87e","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\agoel\\.conda\\envs\\cs229Proj\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\agoel\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n"]},{"name":"stdout","output_type":"stream","text":["0    [[-0.34174502, -0.50928676, 0.1366887, -0.6276...\n","1    [[0.0080082845, -0.085280105, 0.23509698, -0.1...\n","2    [[-0.0092276335, -0.22185859, -0.34482706, 0.0...\n","3    [[-0.11977858, 0.041211575, -0.19592418, -0.13...\n","4    [[-0.31632385, -0.1351991, 0.3966409, -0.03750...\n","Name: bert_embeddings, dtype: object\n"]}],"source":["# Load pre-trained BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Function to generate BERT embeddings\n","def get_bert_embeddings(text):\n","    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n","    outputs = model(**inputs)\n","    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n","\n","# Apply the function to the 'description' column\n","df['bert_embeddings'] = df['description'].apply(lambda x: get_bert_embeddings(x) if pd.notnull(x) else None)\n","\n","print(df['bert_embeddings'].head())"]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer\n","\n","model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and fast\n","df['bert_embeddings'] = df['description'].apply(lambda x: model.encode(x) if pd.notnull(x) else None)"],"metadata":{"id":"iwTisgrNBVsB"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}